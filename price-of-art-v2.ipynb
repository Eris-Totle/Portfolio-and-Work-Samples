{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":46996,"databundleVersionId":5026012,"sourceType":"competition"}],"dockerImageVersionId":30618,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"library(randomForest)\nlibrary(leaps)\nlibrary(tidyverse)\nlibrary(glmnet)\nlibrary(pls)\nlibrary(dbplyr)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(Metrics)\nlibrary(e1071)\nlibrary(doParallel)\nlibrary(ranger)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"train<-read.csv(\"/kaggle/input/the-price-of-art/train.csv\")\ntest<-read.csv(\"/kaggle/input/the-price-of-art/test.csv\")\nsample<-read.csv(\"/kaggle/input/the-price-of-art/sample.csv\")","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(train)\ndim(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA and Cleaning Data","metadata":{}},{"cell_type":"markdown","source":"In looking at the data, it seems we have 16 columns, with 97571 observations. The character columns have a lot of information, so its difficult to know where to begin with these columsn and their impact on sale value. Some clues that I had discovered in researching indicators of art value include the artist, the materials, dimensions of the artwork, origin and transactional history of the artwork. There is some indication that factors including the number of times a piece is exhibited increases its value. This is useful in starting to work with these variables, so I'll start here. Ill first do some cleaning and changing of the dimensions of the artwork. ","metadata":{}},{"cell_type":"code","source":"train$height_cm <- as.numeric(train$height_cm)\ntrain$width_cm <- as.numeric(train$width_cm)\ntest$height_cm <- as.numeric(test$height_cm)\ntest$width_cm <- as.numeric(test$width_cm)\n\n# changing N/A's to median in height/ weight columns\ntrain$height_cm[is.na(train$height_cm)] <- mean(train$height_cm, na.rm = T)\ntrain$width_cm[is.na(train$width_cm)] <- mean(train$width_cm, na.rm = T)\ntrain$dimensions<-(train$height_cm * train$width_cm)\n\n# same for test\ntest$height_cm[is.na(test$height_cm)] <- mean(test$height_cm, na.rm = T)\ntest$width_cm[is.na(test$width_cm)] <- mean(test$width_cm, na.rm = T)\ntest$dimensions<-(test$height_cm * test$width_cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"any(is.na(train$dimensions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! So now we have two new variables: \"top selling artists\" and \"dimensions\". There are a few other columns I am interested in learning more about/ sorting through for a useful data set. I couldn't find anything useful as to whether or not the currency an artwork is originally sold in has an impact on its selling value. Lets just take a quick peek as to whether or not there is any useful clues within the data. ","metadata":{}},{"cell_type":"code","source":"train$original_currency<- as.factor(train$original_currency)\n\n# organize currency by selling value\navg_sales_by_currency <- train %>%\n  group_by(original_currency) %>%\n  summarise(avg_sales = mean(price_realized_usd))\n\n# bar chart of currency values\nggplot(avg_sales_by_currency, aes(x = original_currency, y = avg_sales, fill = original_currency)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"white\") +\n  labs(title = \"Average Sales by Currency Type\",\n       x = \"Currency Type\",\n       y = \"Average Sales (USD)\") +\n  scale_fill_manual(values = c(\"USD\" = \"blue\", \"GBP\" = \"green\", \"HKD\" = \"red\", \"CHF\" = \"yellow\", \"EUR\" = \"orange\", \"CNY\" = \"purple\", \"INR\" = \"black\")) +\n  theme_minimal()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some indication here that paintings original currency in USD, CNY, and HKD turn out to be the top selling paintings. Because we are preparing for regularization methods, one-hot encoding may work best for these variables. I will keep the original factor column in the data and experiment with that as well. ","metadata":{}},{"cell_type":"code","source":"# selecting by acquired from artist\ntrain <- train %>%\n  mutate(source = case_when(\n    grepl(\"acquired.*the artist\", provenance, ignore.case = TRUE) ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n\n# selecting by oil painting\ntrain %>% group_by(source) %>% summarise(mean(price_realized_usd))\ntrain <- train %>%\n  mutate(oil_painting = case_when(\n    grepl(\"\\\\boil\\\\b\", details, ignore.case = TRUE) ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n\n# checking mean sales for oil paintings\ntrain %>% group_by(oil_painting) %>% summarise(mean(price_realized_usd))\n\n# same for test\ntest<- test %>%\n  mutate(source = case_when(\n    grepl(\"acquired.*the artist\", provenance, ignore.case = TRUE) ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n\ntest <- test %>%\n  mutate(oil_painting = case_when(\n    grepl(\"\\\\boil\\\\b\", details, ignore.case = TRUE) ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In researching art and its selling value, it was noted that oil paintings are sometimes valued more. This seemes to be for mixed factors including cost of materials, labour times, and the percieved skill required to make oil paintings. It looks like this may be a factor related to sales (unclear if causal). There seems to be higher average sales for oil paintings than others. This will also be used in the final dataset. ","metadata":{}},{"cell_type":"code","source":"plot(train$estimate_high_usd, train$price_realized_usd)\nplot(train$estimate_low_usd, train$price_realized_usd)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both the estimates show a positive correlation with the actual selling point. This means that even on the lower end of the estimated sale price, the higher the estimated sale value indicates the artwork likely sold for a higher price. That being said, there seem to be a lot of 0's or no estimates in these rows. Either because the data is missing, or there was no assumed estimate for those observations. It looks like these 0's represent a marginal amount of the total observations, so lets clean these columns a bit. ","metadata":{}},{"cell_type":"code","source":"set.seed(123)\n\n# Identify zero values\nzero_indices <- which(train$estimate_high_usd == 0)\n\n# Generate random values within the range of the variable\nrandom_values <- runif(length(zero_indices), min(train$estimate_high_usd), max(train$estimate_high_usd))\n\n# Replace zeros with random values\ntrain$estimate_high_usd[zero_indices] <- random_values\n\n# Same for low estimate\nzero_indices <- which(train$estimate_low_usd == 0)\nrandom_values <- runif(length(zero_indices), min(train$estimate_low_usd), max(train$estimate_low_usd))\ntrain$estimate_low_usd[zero_indices] <- random_values\n\n# test\nzero_indices <- which(test$estimate_high_usd == 0)\nrandom_values1<- runif(length(zero_indices), min(test$estimate_high_usd), max(test$estimate_high_usd))\ntest$estimate_high_usd[zero_indices] <- random_values1\nzero_indices1<- which(test$estimate_low_usd == 0)\nrandom_values1<- runif(length(zero_indices1), min(test$estimate_low_usd), max(test$estimate_low_usd))\ntest$estimate_low_usd[zero_indices1]<-random_values1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train$estimate_high_usd, train$price_realized_usd)\nplot(train$estimate_low_usd, train$price_realized_usd)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For now, I have just assigned the 0's random values throughout the data. It seems like there are some outliers. A bit more research into the outliers may indicate which artist these values belong to, with some details as to why they sold for so high. It may be that they were values sold directly from the artist, and therefore not put on auction to be given estimates. Because we are using regularization regressions, we will leave them as is for now. It may be the case that looking into these 0's and managing them a bit differently could improve the model. Or, it may just reveal some other useful information. For now, we will consider it as is. ","metadata":{}},{"cell_type":"code","source":"# selecting based on currency\ntrain <- train %>%\n  mutate(currency = case_when(\n    original_currency %in% c(\"USD\", \"CNY\") ~ TRUE,\n    TRUE ~ FALSE\n  ))\n\n# same for test\ntest <- test %>%\n  mutate(currency = case_when(\n    original_currency %in% c(\"USD\", \"CNY\") ~ TRUE,\n    TRUE ~ FALSE\n  ))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaned data\nclean_train<-train %>% select(-c(object_id, details, category, artist, height_cm, width_cm, auction, location, details, provenance, literature, exhibited, date, original_currency))\nclean_test<- test %>% select(-c(object_id, details, category, artist, height_cm, width_cm, auction, location, details, provenance, literature, exhibited, date, original_currency))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(clean_train)\nhead(clean_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train <- clean_train %>%\n  mutate(currency = as.character(currency))\n\nclean_test <- clean_test %>%\n  mutate(currency = as.character(currency))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ridge Regression","metadata":{}},{"cell_type":"markdown","source":"Looking into this problem, it seems that the normal rmsle() function has difficulty handling negative values: https://www.rdocumentation.org/packages/Metrics/versions/0.1.4/topics/rmsle. This is tough because ridge can produce negative values. One solution is to change these values to non-negative, though that does introduce some bias. Thanks Molly for the code!","metadata":{}},{"cell_type":"code","source":"x <- model.matrix(price_realized_usd ~., clean_train)[,-3]\ny <- clean_train$price_realized_usd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training and testing sets\nset.seed(123)\ntrain_idx<-sample(1:nrow(clean_train), nrow(clean_train) / 2)\ntest_idx<-setdiff(1:nrow(clean_train), train_idx)\ny.test<-clean_train$price_realized_usd[test_idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid<- 10^seq(-2, 2, length = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set.seed(123)\nridge.mod <- glmnet(x[train_idx,], y[train_idx], alpha = 0, lambda = grid , thresh = 1e-12)\ncv.out <- cv.glmnet(x[train_idx,], y[train_idx], alpha = 0)\nbestlam <- cv.out$lambda.min\nridge_pred <- predict(ridge.mod , s = bestlam, newx = x[test_idx, ])\n\nridge_pred<- pmax(ridge_pred, 0)\ny.test <-pmax(y.test, 0)\n\nrmsle_value <- rmsle(ridge_pred, y.test)\ncat(\"RMSLE:\", rmsle_value, \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, what a journey that was! As with everyone else, it seemed that the problem with this code was determing the best approach for calculating rmsle. I think the issue folks were having is that the rmsle function is incompatible with 0 or negative values. See the attached document: https://www.rdocumentation.org/packages/Metrics/versions/0.1.4/topics/rmsle In order to make it work, I had to manually change the values to non-negative. Though this can introduct some bias, it worked great generating RSMLE. The result is an RMSLE of 1.65. ","metadata":{}},{"cell_type":"markdown","source":"# Lasso Regression","metadata":{}},{"cell_type":"code","source":"set.seed(123)\n\n# Train lasso regression model with cross-validation\ncv_model <- cv.glmnet(x[train_idx,],\n  y[train_idx],\n  alpha = 1,  # \n  nfolds = 5 \n)\n\n# Obtain the best lambda value\nbest_lambda <- cv_model$lambda.min\n\n# Train lasso regression model with the best lambda on the entire training set\nlasso_model <- glmnet(x[train_idx,], y[train_idx], alpha = 1, lambda = best_lambda)\n\npredicted_values <- predict(lasso_model, newx = x[test_idx,])\n\nridge_pred<- pmax(predicted_values, 0)\ny_test <-pmax(y.test, 0)\n\n\nrmsle_value <- rmsle(predicted_values, y.test)\ncat(\"RMSLE:\", rmsle_value, \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used the same RMSLE formula and checked it with my original approach to make sure there wouldnt be much of a difference. Looks good. ","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"# Set up train control\ntrControl <- trainControl(method = \"cv\",\n                          number = 5,\n                          verboseIter = FALSE)\n\ntuneGrid <- expand.grid(.mtry = c(1:6))\n\nstore_maxtrees <- list()\n\n\nfor (ntree in c(200, 400, 500)) {\n  set.seed(123)\n  rf_maxtrees <- train(\n    price_realized_usd ~ .,\n    data = clean_train[train_idx, ],\n    method = \"rf\",\n    metric = \"RMSE\",\n    tuneGrid = tuneGrid,\n    trControl = trControl,\n    nodesize = 14,\n    maxnodes = 24,\n    num.trees = ntree,\n    importance = TRUE, \n  )\n  key <- as.character(ntree)\n  store_maxtrees[[key]] <- rf_maxtrees\n}\n\n# Combine the results\nresults_tree <- resamples(store_maxtrees)\n\n# Summary of the results\nsummary(results_tree)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! Also not an easy process. I found this useful tutorial: https://www.guru99.com/r-random-forest-tutorial.html for how to use cross validation with random forests method = \"rf\" looping through different values of ntree. While this approach was easy to follow, it was taking a long, long time to run under method = \"rf\". Be patient, it does eventually work!","metadata":{}},{"cell_type":"code","source":"# Find the optimal number of trees based on median RMSE\noptimal_ntree_index <- which.min(sapply(store_maxtrees, function(model) min(model$results$RMSE)))\n\n# Retrieve the corresponding optimal number of trees\noptimal_ntree <- as.numeric(names(store_maxtrees)[optimal_ntree_index])\n\n# Print the optimal number of trees\ncat(\"Optimal Number of Trees:\", optimal_ntree, \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_maxtrees$bestTune$num.trees <- optimal_ntree\n\npredictions <- predict(rf_maxtrees, newdata = clean_train[test_idx, ])\n\nrmsle_value <- rmsle(predictions, y.test)\ncat(\"RMSLE:\", rmsle_value, \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random forests 200 shows to be the best fitting model with rmsle 1.44","metadata":{}},{"cell_type":"code","source":"final_rf<- train(\n  price_realized_usd ~ .,\n  data = clean_train[train_idx, ],\n  method = \"rf\",\n  metric = \"RMSE\",\n  tuneGrid = tuneGrid,\n  trControl = trControl,\n  nodesize = 14,\n  maxnodes = 24,\n  num.trees = 200,  \n  importance = TRUE\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like a tree size of 400 performs the best as determined through cross validation. ","metadata":{}},{"cell_type":"code","source":"test_pred <- predict(final_rf, newdata = clean_test)\n\nsubmission <- data.frame(\"object_id\" = clean_test$object_id, \"price_realized_usd\" = test_pred)\n\nwrite_csv(submission,'submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}